{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 1: Install Required Libraries\n",
        "\n",
        "In the first cell of your Colab notebook, install the necessary libraries. LangChain and OpenAI are the primary libraries needed."
      ],
      "metadata": {
        "id": "EcFUQyv47uWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "HsY8Ab3Q7ygr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **LangChain**: A framework for building applications with language models.\n"
      ],
      "metadata": {
        "id": "UyMOg-w97z_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 2:  **Import Libraries and Set Up API Key**\n",
        "\n",
        "In the next cell, import the necessary modules and set up your OpenAI API key. Replace `\"YOUR_API_KEY\"` with your actual OpenAI API key."
      ],
      "metadata": {
        "id": "wRPeaTkK73bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "from openai import OpenAI\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
      ],
      "metadata": {
        "id": "MJG_pQJI77jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **os**: Used to set environment variables.\n",
        "\n",
        "- **LLMChain**: A class in Langchain for creating a chain of language model operations.\n",
        "\n",
        "- **ConversationBufferMemory**: A memory class to store conversation history.\n",
        "\n",
        "- **PromptTemplate**: Used to create prompts for the language model."
      ],
      "metadata": {
        "id": "wMpTP6SMEK_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 3: **Define the Chatbot Logic**\n",
        "\n",
        "Create the chatbot logic using Langchain. This involves setting up the memory, prompt, and chain."
      ],
      "metadata": {
        "id": "DL1VlPlHCast"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize memory to store conversation history\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Define the prompt template\n",
        "prompt = PromptTemplate.from_template(\"Answer the customer's question: {query}\")\n",
        "\n",
        "# Create the LLM chain with OpenAI model\n",
        "chain = LLMChain(llm=OpenAI(), prompt=prompt, memory=memory)\n",
        "\n",
        "# Run the chain with a sample query\n",
        "response = chain.run({\"query\": \"Is the SmartWatch available?\"})\n",
        "print(response)"
      ],
      "metadata": {
        "id": "SDNIwc_mCf11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **ConversationBufferMemory**: Keeps track of the conversation context.\n",
        "\n",
        "- **PromptTemplate**: Formats the prompt to include the user's query.\n",
        "\n",
        "- **LLMChain**: Combines the language model, prompt, and memory to generate responses."
      ],
      "metadata": {
        "id": "UKBoICt4Cii4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 4: **Enter your Query**"
      ],
      "metadata": {
        "id": "5tQcxLnVind9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to simulate user input and get a response\n",
        "def get_response(user_query):\n",
        "    response = chain.run({\"query\": user_query})\n",
        "    return response\n",
        "\n",
        "# Write whatever quesry you want to ask the Chatbot\n",
        "dummy_query = \"What are the features of the SmartWatch?\"\n",
        "response = get_response(dummy_query)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "8pK9e0KAivmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###OR"
      ],
      "metadata": {
        "id": "0NJ6milYjaiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive loop for continuous queries\n",
        "def interactive_chat():\n",
        "    print(\"Welcome to the SmartWatch Support Chatbot!\")\n",
        "    print(\"You can ask about SmartWatch features, pricing, availability, etc.\")\n",
        "    print(\"Type 'exit' to end the chat.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"You: \")\n",
        "        if user_query.lower() == 'exit':\n",
        "            print(\"Chatbot: Thank you for chatting with us. Have a great day!\")\n",
        "            break\n",
        "\n",
        "        response = get_response(user_query)\n",
        "        print(f\"Chatbot: {response}\")\n",
        "\n",
        "        # Suggest a follow-up question\n",
        "        print(\"Chatbot: Would you like to know more about SmartWatch features or pricing?\")\n",
        "\n",
        "# Start the interactive chat\n",
        "interactive_chat()"
      ],
      "metadata": {
        "id": "aPlncqFKjc3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Example Interaction:\n",
        "\n",
        "Here's how a session might look when you run the `interactive_chat` function:"
      ],
      "metadata": {
        "id": "41RPC9edjwf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# Welcome to the SmartWatch Support Chatbot!\n",
        "You can ask about SmartWatch features, pricing, availability, etc.\n",
        "Type 'exit' to end the chat.\n",
        "\n",
        "You: What are the features of the SmartWatch?\n",
        "Chatbot: The SmartWatch includes features such as heart rate monitoring, GPS tracking, and water resistance.\n",
        "Chatbot: Would you like to know more about SmartWatch features or pricing?\n",
        "\n",
        "You: How much does it cost?\n",
        "Chatbot: The SmartWatch is priced at $299.99.\n",
        "Chatbot: Would you like to know more about SmartWatch features or pricing?\n",
        "\n",
        "You: exit\n",
        "Chatbot: Thank you for chatting with us. Have a great day!\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "jL37EBbPj1vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Additional Resources\n",
        "\n",
        "- **OpenAI API Documentation**: [OpenAI API Docs](https://beta.openai.com/docs/)\n",
        "- **Langchain GitHub**: [Langchain GitHub](https://github.com/langchain/langchain)"
      ],
      "metadata": {
        "id": "kh8AN6BY8Wjb"
      }
    }
  ]
}